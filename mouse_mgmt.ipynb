{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from ColonyMgmt import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# to do items\n",
    "# add logging function; if colony is over 200, prioritize saccing and consolidating cages\n",
    "\n",
    "## some fancy to dos:\n",
    "### check that the csv is within an hour, i.e. up to date\n",
    "### wrap helper functions more cleanly?\n",
    "### eventually package as a script proper\n",
    "### function to search the **NOTES** column; i.e. for mice that have bred with other mice etc\n",
    "\n",
    "## some fiddling to make sure we are not pulling from the wrong file\n",
    "# file = \"05227_mastersheet - Active.tsv\"\n",
    "\n",
    "# def checkTime(path):\n",
    "#     loc = os.getcwd() + \"\\\\\" + path\n",
    "#     return os.path.getmtime(loc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## some useful helper functions to consider\n",
    "makefn('string') #uatomatically takes string, appends date + .csv\n",
    "\n",
    "### masking\n",
    "ins = (df.Lineage.str.contains(\"ins\")) #TRUE when lineage contains ins\n",
    "pbf = (df.Lineage.str.contains(\"PBF\")) #TRUE when lineage contains PBF\n",
    "insPBF = df[ins | pbf].copy()  # boolean operator -- include rows where either is TRUE\n",
    "\n",
    "### helpful consolidators\n",
    "makeConsolidations(df,\n",
    "                   save = True,\n",
    "                   popBack = False)  # creates two dataframes of all cages + dispensible % > .2, and either saves them independently or pops them back for  further manip\n",
    "\n",
    "### helpful for euthanizing many animals\n",
    "df.fillna(\"-\").groupby(['Cage','DOD']).agg({'Tag':'unique', 'Lineage': 'unique'}).to_csv(fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## this is all the functions now contained in mouse_mgmt import\n",
    "# # def importCleanDF(fn, sep = \"\\t\",\n",
    "#                   skip = 0,\n",
    "#                   dropDeads = False,\n",
    "#                   dropTransfers = True,\n",
    "#                   dropHeaders = False,\n",
    "#                   convertDOB = True,\n",
    "#                   calcDispensables = True,\n",
    "#                   stats=True):\n",
    "#     '''skip rangi(0,9) for Harvard mastersheet\n",
    "#     dropHeaders = True for Harvard Mas\"'''\n",
    "    \n",
    "#     df = pd.read_csv(fn, sep = sep,\n",
    "#                      skiprows = skip,\n",
    "#                      parse_dates = True,\n",
    "#                     dtype=str).dropna(axis = 0, how = 'all')\n",
    "#     print(\"Read in CSV\",fn) #logging\n",
    "    \n",
    "#     df.Sex = df.Sex.fillna(\"temp\") \n",
    "#     print(\"Animals without gender given temp. gender\") #if animals are not gendered\n",
    "    \n",
    "#     df.Cage = df.Cage.fillna('not included yet') #if animals are missing a cage\n",
    "#     print(\"Animals without cage given temp. cage\") #if animals are not gendered\n",
    "\n",
    "#     df = parseDOD(df, drop = dropDeads)\n",
    "    \n",
    "#     if dropTransfers:\n",
    "#         df = dropTransferred(df)\n",
    "        \n",
    "#     if dropHeaders:\n",
    "#         df = df[df.Cage.str.contains(\"NRB|HAT|HOP\",\n",
    "#                                  case=False,\n",
    "#                                  na=False)].reset_index(drop=True) #drop the header rows & reset the index\n",
    "#         print(\"Retained rows with NRB, HAT, HOP, dropped otherwise drop headers\")\n",
    "        \n",
    "#     if convertDOB:\n",
    "#         df.DOB = cleanDOBs(df.DOB)\n",
    "#     if calcDispensables:\n",
    "#         df = calcDisp(df)\n",
    "#     if df.Ear.any():\n",
    "#         df.Ear =  df.Ear.apply(lambda row: \"\\'\" + row if type(row)== str else np.nan) #convert ear tags to excel-clean formats\n",
    "#         print(\"Parsed ear tags for Excel formatting\")  \n",
    "#     if stats:\n",
    "#         colonyStats(df)\n",
    "#     return df\n",
    "\n",
    "# # def cleanDOBs(s):\n",
    "# #     '''uses .map() to apply changes'''\n",
    "# #     dates = {date:pd.to_datetime(date, errors = 'coerce') for date in s.unique()}\n",
    "# #     return s.map(dates)\n",
    "# # def parseDOD(df, drop = True):\n",
    "# #     df['DOD'] =  df.DOD.apply(lambda row: row.strip().lower() if type(row)== str else np.nan) #convert ear tags to excel-clean formats\n",
    "# #     df['parsedDOD'] = pd.to_datetime(df.DOD, errors = 'coerce')\n",
    "# #     if drop:\n",
    "# #         init = colonyStats(df)\n",
    "# #         df = df[(~df.parsedDOD.notnull()) \\\n",
    "# #                 & (~df.DOD.str.contains('sperm|Diss|f.d.|mia.',\n",
    "# #                                    na = False))] #drop assorted dead mice\n",
    "# #         print(\"initial counts:\", init, \"\\nafter dropping dead\", colonyStats(df))\n",
    "# #     return df\n",
    "\n",
    "\n",
    "\n",
    "# #     return df      \n",
    "# # def dropTransferred(df):\n",
    "# #     init = colonyStats(df)\n",
    "# #     df = df[~df.DOD.str.contains('transfer', na = False)]\n",
    "# #     fin = colonyStats(df)\n",
    "# #     print('after removing transferred', fin)\n",
    "# #     return df\n",
    "# # def collectAgeRange(df,\n",
    "# #                     on_date,\n",
    "# #                     oldest_requested_age,\n",
    "# #                     youngest_requested_age,\n",
    "# #                     lineage,\n",
    "# #                     gender):\n",
    "# #     early = pd.to_datetime(on_date) - pd.Timedelta(weeks = oldest_requested_age)\n",
    "# #     late = pd.to_datetime(on_date) - pd.Timedelta(weeks = youngest_requested_age)\n",
    "# #     mask = (df['DOB'] >= early)\\\n",
    "# #             & (df['DOB'] <= late)\\\n",
    "# #             & (df['Lineage'].str.contains(lineage))\\\n",
    "# #             & (df['Sex'].str.contains(gender))\n",
    "# #     return early, late, mask\n",
    "# # def colonyStats(df):\n",
    "# #     '''helper function: returns number of mice, number of cages'''\n",
    "# #     num_cages = len(df.Cage.unique())\n",
    "# #     stats = {'numCages':len(df.Cage.unique()), 'numMice' : len(df)}\n",
    "# #     if num_cages >=200:\n",
    "# #         print(\"certainly cage reorg time\")\n",
    "# #     return stats\n",
    "# # def makefn(string):\n",
    "# #     '''returns string + formatted date to use as a file name'''\n",
    "# #     return string + str(dt.today().strftime(\"_%Y-%B-%d\")) + \".csv\"\n",
    "# # def tagSearch(string, df, column=\"Tag\"):\n",
    "# #     '''from a string, extracts all numbers and then searches for those numbers in a column'''\n",
    "# #     find_t = re.findall(r'\\d+', string)\n",
    "# #     #search for that list in the spreadsheet and return only those rows\n",
    "# #     return df[column].isin(find_t)\n",
    "# # def makeOutputs(df, upcase=True):\n",
    "# #     '''extremely specific to produce dispensible & sorted cage information'''\n",
    "# #     fineGrainedDispense = df.query(\"Dispensible >= 0.2\").sort_values([\"Dispensible\", \"Cage\"], ascending=False)\n",
    "# #     cages = df.groupby(\"Cage\").agg({'Dispensible':'first', #could be cleaner\n",
    "# #                                     'Cage':'size', #yay!\n",
    "# #                                     'Sex':'unique', #yay!\n",
    "# #                                     'Color':'unique',\n",
    "# #                                    'DOD':'unique'})   #yay!\n",
    "# #     return fineGrainedDispense, cages\n",
    "# # def calcTotals(df):\n",
    "# #     counted = df.groupby(\"Cage\").agg('size').reset_index(name='Total')\n",
    "# #     return df.merge(counted)\n",
    "# # def calcDisp(df):\n",
    "# #     disp = df.groupby(\"Cage\").DOD\\\n",
    "# #                 .value_counts(normalize=True,\n",
    "# #                               dropna = False).unstack()\n",
    "# #     if 'Dispensible' in disp:\n",
    "# #         disp = disp.Dispensible.reset_index()\n",
    "# #         print(\"Dispensible counts normalized + totals calculated\")\n",
    "# #         df = df.merge(disp)\n",
    "# #     else:\n",
    "# #         print(\"No dispensible mice, returning original DF with totals added\")\n",
    "# #     return calcTotals(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '05227_mastersheet - HopkinsColony.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mtime: 2020-10-15 13:56:58\n"
     ]
    }
   ],
   "source": [
    "ts = os.path.getmtime(file)\n",
    "print(\"mtime:\", dt.utcfromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in CSV 05227_mastersheet - HopkinsColony.tsv\n",
      "Animals without gender given temp. gender\n",
      "Animals without cage given temp. cage\n",
      "Animals without specified lineage given NA\n",
      "calculted total dispensible counts\n",
      "calculated total cage sizes\n",
      "calculated % disp\n",
      "certainly cage reorg time\n",
      "certainly cage reorg time\n",
      "after removing transferred {'numCages': 200, 'numMice': 538}\n",
      "Parsed ear tags for Excel formatting\n",
      "certainly cage reorg time\n"
     ]
    }
   ],
   "source": [
    "df = importCleanDF(file,\n",
    "                   dropDeads=False,\n",
    "                   dropTransfers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cage</th>\n",
       "      <th>DOD</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOD</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>41</td>\n",
       "      <td>[-]</td>\n",
       "      <td>[5116, 5178, 5222, 5258, 5261, 5262, 5263, 526...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>07/17/20</th>\n",
       "      <td>1</td>\n",
       "      <td>[07/17/20]</td>\n",
       "      <td>[5317]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/20/2020</th>\n",
       "      <td>1</td>\n",
       "      <td>[1/20/2020]</td>\n",
       "      <td>[2618]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/3/2019</th>\n",
       "      <td>1</td>\n",
       "      <td>[1/3/2019]</td>\n",
       "      <td>[2617, 2619]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10/08/20 f.d.</th>\n",
       "      <td>1</td>\n",
       "      <td>[10/08/20 f.d.]</td>\n",
       "      <td>[5113]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11/23/2019</th>\n",
       "      <td>1</td>\n",
       "      <td>[11/23/2019]</td>\n",
       "      <td>[2616]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020/04/06 - f.d.</th>\n",
       "      <td>1</td>\n",
       "      <td>[2020/04/06 - f.d.]</td>\n",
       "      <td>[5224]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/12/2020</th>\n",
       "      <td>1</td>\n",
       "      <td>[3/12/2020]</td>\n",
       "      <td>[2713]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/17/2020</th>\n",
       "      <td>31</td>\n",
       "      <td>[3/17/2020]</td>\n",
       "      <td>[2463, 2633, 2622, 2625, 2620, 2632, 2623, 262...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/24/2020</th>\n",
       "      <td>1</td>\n",
       "      <td>[3/24/2020]</td>\n",
       "      <td>[2741, 2743]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/1/2020</th>\n",
       "      <td>3</td>\n",
       "      <td>[5/1/2020]</td>\n",
       "      <td>[2664, 2662, 2548, 2663, 2549]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/12/2020</th>\n",
       "      <td>15</td>\n",
       "      <td>[5/12/2020]</td>\n",
       "      <td>[2325, 2642, 2643, 2639, 2613, 2703, 2411, 261...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/7/2020</th>\n",
       "      <td>28</td>\n",
       "      <td>[5/7/2020]</td>\n",
       "      <td>[5001, 5002, 5003, 5008, 5009, 5010, 5011, 501...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/8/2020</th>\n",
       "      <td>4</td>\n",
       "      <td>[5/8/2020]</td>\n",
       "      <td>[5300, 5301, 5302, 5303, 5304, 5305, 5306, 532...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6/18/2020</th>\n",
       "      <td>26</td>\n",
       "      <td>[6/18/2020]</td>\n",
       "      <td>[5006, 5007, 5013, 5015, 5016, 5017, 5045, 504...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8/2/2020</th>\n",
       "      <td>1</td>\n",
       "      <td>[8/2/2020]</td>\n",
       "      <td>[5171]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8/26/20</th>\n",
       "      <td>1</td>\n",
       "      <td>[8/26/20]</td>\n",
       "      <td>[5315]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8/26/2020</th>\n",
       "      <td>1</td>\n",
       "      <td>[8/26/2020]</td>\n",
       "      <td>[5212]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8/3/2019</th>\n",
       "      <td>1</td>\n",
       "      <td>[8/3/2019]</td>\n",
       "      <td>[5292]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8/7/2020</th>\n",
       "      <td>1</td>\n",
       "      <td>[8/7/2020]</td>\n",
       "      <td>[5098, 5100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9/30/2020</th>\n",
       "      <td>1</td>\n",
       "      <td>[9/30/2020]</td>\n",
       "      <td>[5198]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breeder-backup</th>\n",
       "      <td>1</td>\n",
       "      <td>[breeder-backup]</td>\n",
       "      <td>[5324]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breeder-jun01</th>\n",
       "      <td>6</td>\n",
       "      <td>[breeder-jun01]</td>\n",
       "      <td>[5028, 5181, 5179, 5219, 5227, 5325]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breeder-jun01backup</th>\n",
       "      <td>3</td>\n",
       "      <td>[breeder-jun01backup]</td>\n",
       "      <td>[5172, 5201, 5229*]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breeder-may20</th>\n",
       "      <td>23</td>\n",
       "      <td>[breeder-may20]</td>\n",
       "      <td>[5004, 5280, 5137, 5014, 5094, 5283, 5047, 505...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breeding</th>\n",
       "      <td>1</td>\n",
       "      <td>[breeding]</td>\n",
       "      <td>[5259, 5260]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breeding - xcas9 f, experimental</th>\n",
       "      <td>1</td>\n",
       "      <td>[breeding - xcas9 f, experimental]</td>\n",
       "      <td>[2401]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breeding-confirmed-201014</th>\n",
       "      <td>5</td>\n",
       "      <td>[breeding-confirmed-201014]</td>\n",
       "      <td>[5042, 5044, 5363, 5367, 5368, 5369, 5370, 537...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breeding-putative-201015</th>\n",
       "      <td>14</td>\n",
       "      <td>[breeding-putative-201015]</td>\n",
       "      <td>[5245, 5005, 5239, 5279, 5270, 5273, 5242, 529...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dispensible</th>\n",
       "      <td>19</td>\n",
       "      <td>[dispensible]</td>\n",
       "      <td>[5029, 5103, 5104, 5043, 5115, 5132, 5180, 513...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dispensible (presumed dead) (requested euthanasia)</th>\n",
       "      <td>1</td>\n",
       "      <td>[dispensible (presumed dead) (requested euthan...</td>\n",
       "      <td>[5257*]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f.d. 07/20/20</th>\n",
       "      <td>1</td>\n",
       "      <td>[f.d. 07/20/20]</td>\n",
       "      <td>[5278]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f.d. 2020-02-14</th>\n",
       "      <td>1</td>\n",
       "      <td>[f.d. 2020-02-14]</td>\n",
       "      <td>[2731]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>requested euthanasia</th>\n",
       "      <td>12</td>\n",
       "      <td>[requested euthanasia]</td>\n",
       "      <td>[5034, 5035, 5036, 5048, 5059, 5060, 5061, 507...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>requested euthanasia, likely date of 5/07</th>\n",
       "      <td>1</td>\n",
       "      <td>[requested euthanasia, likely date of 5/07]</td>\n",
       "      <td>[5253, 5254]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reserve-may20</th>\n",
       "      <td>3</td>\n",
       "      <td>[reserve-may20]</td>\n",
       "      <td>[5135, 5136, 5187, 5213]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vickie (experimental)</th>\n",
       "      <td>4</td>\n",
       "      <td>[vickie (experimental)]</td>\n",
       "      <td>[5307, 5308, 5309, 5310, 5311, 5316, 5319, 532...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Cage  \\\n",
       "DOD                                                        \n",
       "-                                                     41   \n",
       "07/17/20                                               1   \n",
       "1/20/2020                                              1   \n",
       "1/3/2019                                               1   \n",
       "10/08/20 f.d.                                          1   \n",
       "11/23/2019                                             1   \n",
       "2020/04/06 - f.d.                                      1   \n",
       "3/12/2020                                              1   \n",
       "3/17/2020                                             31   \n",
       "3/24/2020                                              1   \n",
       "5/1/2020                                               3   \n",
       "5/12/2020                                             15   \n",
       "5/7/2020                                              28   \n",
       "5/8/2020                                               4   \n",
       "6/18/2020                                             26   \n",
       "8/2/2020                                               1   \n",
       "8/26/20                                                1   \n",
       "8/26/2020                                              1   \n",
       "8/3/2019                                               1   \n",
       "8/7/2020                                               1   \n",
       "9/30/2020                                              1   \n",
       "breeder-backup                                         1   \n",
       "breeder-jun01                                          6   \n",
       "breeder-jun01backup                                    3   \n",
       "breeder-may20                                         23   \n",
       "breeding                                               1   \n",
       "breeding - xcas9 f, experimental                       1   \n",
       "breeding-confirmed-201014                              5   \n",
       "breeding-putative-201015                              14   \n",
       "dispensible                                           19   \n",
       "dispensible (presumed dead) (requested euthanasia)     1   \n",
       "f.d. 07/20/20                                          1   \n",
       "f.d. 2020-02-14                                        1   \n",
       "requested euthanasia                                  12   \n",
       "requested euthanasia, likely date of 5/07              1   \n",
       "reserve-may20                                          3   \n",
       "vickie (experimental)                                  4   \n",
       "\n",
       "                                                                                                  DOD  \\\n",
       "DOD                                                                                                     \n",
       "-                                                                                                 [-]   \n",
       "07/17/20                                                                                   [07/17/20]   \n",
       "1/20/2020                                                                                 [1/20/2020]   \n",
       "1/3/2019                                                                                   [1/3/2019]   \n",
       "10/08/20 f.d.                                                                         [10/08/20 f.d.]   \n",
       "11/23/2019                                                                               [11/23/2019]   \n",
       "2020/04/06 - f.d.                                                                 [2020/04/06 - f.d.]   \n",
       "3/12/2020                                                                                 [3/12/2020]   \n",
       "3/17/2020                                                                                 [3/17/2020]   \n",
       "3/24/2020                                                                                 [3/24/2020]   \n",
       "5/1/2020                                                                                   [5/1/2020]   \n",
       "5/12/2020                                                                                 [5/12/2020]   \n",
       "5/7/2020                                                                                   [5/7/2020]   \n",
       "5/8/2020                                                                                   [5/8/2020]   \n",
       "6/18/2020                                                                                 [6/18/2020]   \n",
       "8/2/2020                                                                                   [8/2/2020]   \n",
       "8/26/20                                                                                     [8/26/20]   \n",
       "8/26/2020                                                                                 [8/26/2020]   \n",
       "8/3/2019                                                                                   [8/3/2019]   \n",
       "8/7/2020                                                                                   [8/7/2020]   \n",
       "9/30/2020                                                                                 [9/30/2020]   \n",
       "breeder-backup                                                                       [breeder-backup]   \n",
       "breeder-jun01                                                                         [breeder-jun01]   \n",
       "breeder-jun01backup                                                             [breeder-jun01backup]   \n",
       "breeder-may20                                                                         [breeder-may20]   \n",
       "breeding                                                                                   [breeding]   \n",
       "breeding - xcas9 f, experimental                                   [breeding - xcas9 f, experimental]   \n",
       "breeding-confirmed-201014                                                 [breeding-confirmed-201014]   \n",
       "breeding-putative-201015                                                   [breeding-putative-201015]   \n",
       "dispensible                                                                             [dispensible]   \n",
       "dispensible (presumed dead) (requested euthanasia)  [dispensible (presumed dead) (requested euthan...   \n",
       "f.d. 07/20/20                                                                         [f.d. 07/20/20]   \n",
       "f.d. 2020-02-14                                                                     [f.d. 2020-02-14]   \n",
       "requested euthanasia                                                           [requested euthanasia]   \n",
       "requested euthanasia, likely date of 5/07                 [requested euthanasia, likely date of 5/07]   \n",
       "reserve-may20                                                                         [reserve-may20]   \n",
       "vickie (experimental)                                                         [vickie (experimental)]   \n",
       "\n",
       "                                                                                                  Tag  \n",
       "DOD                                                                                                    \n",
       "-                                                   [5116, 5178, 5222, 5258, 5261, 5262, 5263, 526...  \n",
       "07/17/20                                                                                       [5317]  \n",
       "1/20/2020                                                                                      [2618]  \n",
       "1/3/2019                                                                                 [2617, 2619]  \n",
       "10/08/20 f.d.                                                                                  [5113]  \n",
       "11/23/2019                                                                                     [2616]  \n",
       "2020/04/06 - f.d.                                                                              [5224]  \n",
       "3/12/2020                                                                                      [2713]  \n",
       "3/17/2020                                           [2463, 2633, 2622, 2625, 2620, 2632, 2623, 262...  \n",
       "3/24/2020                                                                                [2741, 2743]  \n",
       "5/1/2020                                                               [2664, 2662, 2548, 2663, 2549]  \n",
       "5/12/2020                                           [2325, 2642, 2643, 2639, 2613, 2703, 2411, 261...  \n",
       "5/7/2020                                            [5001, 5002, 5003, 5008, 5009, 5010, 5011, 501...  \n",
       "5/8/2020                                            [5300, 5301, 5302, 5303, 5304, 5305, 5306, 532...  \n",
       "6/18/2020                                           [5006, 5007, 5013, 5015, 5016, 5017, 5045, 504...  \n",
       "8/2/2020                                                                                       [5171]  \n",
       "8/26/20                                                                                        [5315]  \n",
       "8/26/2020                                                                                      [5212]  \n",
       "8/3/2019                                                                                       [5292]  \n",
       "8/7/2020                                                                                 [5098, 5100]  \n",
       "9/30/2020                                                                                      [5198]  \n",
       "breeder-backup                                                                                 [5324]  \n",
       "breeder-jun01                                                    [5028, 5181, 5179, 5219, 5227, 5325]  \n",
       "breeder-jun01backup                                                               [5172, 5201, 5229*]  \n",
       "breeder-may20                                       [5004, 5280, 5137, 5014, 5094, 5283, 5047, 505...  \n",
       "breeding                                                                                 [5259, 5260]  \n",
       "breeding - xcas9 f, experimental                                                               [2401]  \n",
       "breeding-confirmed-201014                           [5042, 5044, 5363, 5367, 5368, 5369, 5370, 537...  \n",
       "breeding-putative-201015                            [5245, 5005, 5239, 5279, 5270, 5273, 5242, 529...  \n",
       "dispensible                                         [5029, 5103, 5104, 5043, 5115, 5132, 5180, 513...  \n",
       "dispensible (presumed dead) (requested euthanasia)                                            [5257*]  \n",
       "f.d. 07/20/20                                                                                  [5278]  \n",
       "f.d. 2020-02-14                                                                                [2731]  \n",
       "requested euthanasia                                [5034, 5035, 5036, 5048, 5059, 5060, 5061, 507...  \n",
       "requested euthanasia, likely date of 5/07                                                [5253, 5254]  \n",
       "reserve-may20                                                                [5135, 5136, 5187, 5213]  \n",
       "vickie (experimental)                               [5307, 5308, 5309, 5310, 5311, 5316, 5319, 532...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['DOD']).agg({'Cage': 'nunique', 'DOD':'unique', 'Tag': 'unique'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('DOD == \"breeding-putative-201015\"')[easyCats].sort_values('DOB').to_csv(makefn('PB7_breeders'), sep = \"\\t\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## vickie cages\n",
    "# # mutant:\n",
    "# AA0105 AA0105\n",
    "# AA0056 5171-5174 (WT / syn cre relevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CSV with fns AllCages_2020-August-06.csv\n",
      "Saved CSV with fns FemaleCons_2020-August-06.csv\n",
      "returning 2 frames\n"
     ]
    }
   ],
   "source": [
    "frames = makeConsolidations(df, popBack=True, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "easyCats.append('Genotype')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('Cage.str.contains(\"AA0105|AA0056\")')[easyCats].to_clipboard(index = False, sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('Cage.str.contains(\"AA0105|AA0056\")')[['Tag', 'Cage', 'Ear', 'Sex', 'Color', 'DOB', 'Lineage']].to_clipboard(index = False, sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mice = df.fillna(\"-\").query('Tag.str.contains(\"5049|5253|5254|5242\")')\n",
    "cages = mice.Cage.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cages = mice.Cage.unique()\n",
    "df[df.Cage.isin(cages)][easyCats].to_clipboard(index = False, sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tag', 'Cage', 'Ear', 'Sex', 'Color', 'DOB', 'Lineage', 'Plate']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Cage</th>\n",
       "      <th>Ear</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Color</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Lineage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5034</td>\n",
       "      <td>AA0010</td>\n",
       "      <td>'+/t</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>fCas9 x hCD2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5035</td>\n",
       "      <td>AA0010</td>\n",
       "      <td>'++/t</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>fCas9 x hCD2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5036</td>\n",
       "      <td>AA0010</td>\n",
       "      <td>'t/+</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>fCas9 x hCD2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>5048</td>\n",
       "      <td>AA0010</td>\n",
       "      <td>'+/t</td>\n",
       "      <td>F</td>\n",
       "      <td>Agouti</td>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>1685ins21#2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5049</td>\n",
       "      <td>AA0010</td>\n",
       "      <td>'++/t</td>\n",
       "      <td>F</td>\n",
       "      <td>Agouti</td>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>1685ins21#2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>5242</td>\n",
       "      <td>AA0079</td>\n",
       "      <td>'+/t</td>\n",
       "      <td>F</td>\n",
       "      <td>Black</td>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>1763PB#7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>5243</td>\n",
       "      <td>AA0079</td>\n",
       "      <td>'++/t</td>\n",
       "      <td>F</td>\n",
       "      <td>Black</td>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>1763PB#7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>5298</td>\n",
       "      <td>AA0079</td>\n",
       "      <td>'+/t</td>\n",
       "      <td>F</td>\n",
       "      <td>Albino</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>1763PB#7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>5299</td>\n",
       "      <td>AA0079</td>\n",
       "      <td>'t/+</td>\n",
       "      <td>F</td>\n",
       "      <td>Albino</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>1763PB#7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>5253</td>\n",
       "      <td>AA0082</td>\n",
       "      <td>'+/t</td>\n",
       "      <td>F</td>\n",
       "      <td>Agouti</td>\n",
       "      <td>2020-02-11</td>\n",
       "      <td>1763PB#7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>5254</td>\n",
       "      <td>AA0082</td>\n",
       "      <td>'++/t</td>\n",
       "      <td>F</td>\n",
       "      <td>Black</td>\n",
       "      <td>2020-02-11</td>\n",
       "      <td>1763PB#7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tag    Cage    Ear Sex   Color        DOB       Lineage\n",
       "36   5034  AA0010   '+/t   F     NaN 2019-12-31  fCas9 x hCD2\n",
       "37   5035  AA0010  '++/t   F     NaN 2019-12-31  fCas9 x hCD2\n",
       "38   5036  AA0010   't/+   F     NaN 2019-12-31  fCas9 x hCD2\n",
       "39   5048  AA0010   '+/t   F  Agouti 2019-12-30   1685ins21#2\n",
       "40   5049  AA0010  '++/t   F  Agouti 2019-12-30   1685ins21#2\n",
       "195  5242  AA0079   '+/t   F   Black 2020-02-05      1763PB#7\n",
       "196  5243  AA0079  '++/t   F   Black 2020-02-05      1763PB#7\n",
       "197  5298  AA0079   '+/t   F  Albino 2020-04-01      1763PB#7\n",
       "198  5299  AA0079   't/+   F  Albino 2020-04-01      1763PB#7\n",
       "206  5253  AA0082   '+/t   F  Agouti 2020-02-11      1763PB#7\n",
       "207  5254  AA0082  '++/t   F   Black 2020-02-11      1763PB#7"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Cage.isin(cages)][['Tag', 'Cage', 'Ear', 'Sex', 'Color', 'DOB', 'Lineage']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code from summing total hgRNA counts for collecting animal samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## splitting hgRNA genotypes into columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## speciality speed code for re-splitting genotypes by hgRNA tyep\n",
    "def splitGenotypes(df):\n",
    "    split = df['Genotype'].str.split(r'(\\w,)', expand=True)\n",
    "    split[6] = split[6].str.extract('(\\d+)')\n",
    "    split = split.rename({\n",
    "        0: \"E\",\n",
    "        2: 'I',\n",
    "        4: \"S\",\n",
    "        6: 'ina'\n",
    "    }, axis=1).drop(columns=[1, 3, 5])\n",
    "\n",
    "    return split\n",
    "\n",
    "\n",
    "split = splitGenotypes(df)\n",
    "newcols = []\n",
    "oldcols = []\n",
    "for col in split:\n",
    "    colN = str(col) + \"_num\"\n",
    "    split[colN] = pd.to_numeric(split[col], errors='coerce')\n",
    "    oldcols.append(col)\n",
    "    newcols.append(colN)\n",
    "\n",
    "split['summedhgRNAs'] = split[newcols].sum(axis=1)\n",
    "split['summedhgRNAs_active'] = split[newcols[0:3]].sum(axis=1)\n",
    "split = split.drop(oldcols[0:4], axis=1)\n",
    "df = df.merge(split, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Cage</th>\n",
       "      <th>Ear</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Color</th>\n",
       "      <th>Name</th>\n",
       "      <th>Genotype</th>\n",
       "      <th>DOB</th>\n",
       "      <th>DOD</th>\n",
       "      <th>Father</th>\n",
       "      <th>...</th>\n",
       "      <th>parsedDOD</th>\n",
       "      <th>DispCount</th>\n",
       "      <th>CageSize</th>\n",
       "      <th>DispPercent</th>\n",
       "      <th>E_num</th>\n",
       "      <th>I_num</th>\n",
       "      <th>S_num</th>\n",
       "      <th>ina_num</th>\n",
       "      <th>summedhgRNAs</th>\n",
       "      <th>summedhgRNAs_active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2401</td>\n",
       "      <td>HOP0003</td>\n",
       "      <td>'+/+t</td>\n",
       "      <td>M</td>\n",
       "      <td>Albino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5E,10I,20S,10ina</td>\n",
       "      <td>2019-05-28</td>\n",
       "      <td>breeding - xcas9 f, experimental</td>\n",
       "      <td>1732</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2662</td>\n",
       "      <td>NRB1073-A</td>\n",
       "      <td>'-/ot</td>\n",
       "      <td>F</td>\n",
       "      <td>Gray</td>\n",
       "      <td>J024858-Cas9</td>\n",
       "      <td>J024858-Cas9</td>\n",
       "      <td>2019-08-16</td>\n",
       "      <td>dispensible, check for pregnancies and euthani...</td>\n",
       "      <td>2065</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2548</td>\n",
       "      <td>NRB1073-A</td>\n",
       "      <td>'-/ot</td>\n",
       "      <td>M</td>\n",
       "      <td>Black</td>\n",
       "      <td>J024858-Cas9</td>\n",
       "      <td>J024858-Cas9</td>\n",
       "      <td>2019-07-16</td>\n",
       "      <td>dispensible</td>\n",
       "      <td>2065</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2663</td>\n",
       "      <td>NRB1073-B</td>\n",
       "      <td>'-/ot</td>\n",
       "      <td>F</td>\n",
       "      <td>Gray</td>\n",
       "      <td>J024858-Cas9</td>\n",
       "      <td>J024858-Cas9</td>\n",
       "      <td>2019-08-16</td>\n",
       "      <td>dispensible, check for pregnancies and euthani...</td>\n",
       "      <td>2065</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2549</td>\n",
       "      <td>NRB1073-B</td>\n",
       "      <td>'-/ot</td>\n",
       "      <td>M</td>\n",
       "      <td>Black</td>\n",
       "      <td>J024858-Cas9</td>\n",
       "      <td>J024858-Cas9</td>\n",
       "      <td>2019-07-16</td>\n",
       "      <td>dispensible</td>\n",
       "      <td>2065</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>5322</td>\n",
       "      <td>AA0106</td>\n",
       "      <td>'t/++</td>\n",
       "      <td>F</td>\n",
       "      <td>Agouti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04-10</td>\n",
       "      <td>-</td>\n",
       "      <td>2550</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>5323</td>\n",
       "      <td>AA0106</td>\n",
       "      <td>'notch-5</td>\n",
       "      <td>F</td>\n",
       "      <td>Agouti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04-10</td>\n",
       "      <td>-</td>\n",
       "      <td>2550</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>5324</td>\n",
       "      <td>AA0107</td>\n",
       "      <td>'+/t</td>\n",
       "      <td>F</td>\n",
       "      <td>Black</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fCas9 MT(+/+), synCre (+)</td>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>breeder-backup</td>\n",
       "      <td>2728</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>5325</td>\n",
       "      <td>AA0107</td>\n",
       "      <td>'++/t</td>\n",
       "      <td>F</td>\n",
       "      <td>Black</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fCas9 MT(+/+), synCre (+)</td>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>breeder-jun01</td>\n",
       "      <td>2728</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>5326</td>\n",
       "      <td>AA0107</td>\n",
       "      <td>'t/+</td>\n",
       "      <td>F</td>\n",
       "      <td>Black</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fCas9 MT(+/+), synCre (-)</td>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>dispensible</td>\n",
       "      <td>2728</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tag       Cage       Ear Sex   Color          Name  \\\n",
       "6    2401    HOP0003     '+/+t   M  Albino           NaN   \n",
       "7    2662  NRB1073-A     '-/ot   F    Gray  J024858-Cas9   \n",
       "8    2548  NRB1073-A     '-/ot   M   Black  J024858-Cas9   \n",
       "9    2663  NRB1073-B     '-/ot   F    Gray  J024858-Cas9   \n",
       "10   2549  NRB1073-B     '-/ot   M   Black  J024858-Cas9   \n",
       "..    ...        ...       ...  ..     ...           ...   \n",
       "251  5322     AA0106     't/++   F  Agouti           NaN   \n",
       "252  5323     AA0106  'notch-5   F  Agouti           NaN   \n",
       "253  5324     AA0107      '+/t   F   Black           NaN   \n",
       "254  5325     AA0107     '++/t   F   Black           NaN   \n",
       "255  5326     AA0107      't/+   F   Black           NaN   \n",
       "\n",
       "                      Genotype        DOB  \\\n",
       "6             5E,10I,20S,10ina 2019-05-28   \n",
       "7                 J024858-Cas9 2019-08-16   \n",
       "8                 J024858-Cas9 2019-07-16   \n",
       "9                 J024858-Cas9 2019-08-16   \n",
       "10                J024858-Cas9 2019-07-16   \n",
       "..                         ...        ...   \n",
       "251                        NaN 2020-04-10   \n",
       "252                        NaN 2020-04-10   \n",
       "253  fCas9 MT(+/+), synCre (+) 2020-03-24   \n",
       "254  fCas9 MT(+/+), synCre (+) 2020-03-24   \n",
       "255  fCas9 MT(+/+), synCre (-) 2020-03-24   \n",
       "\n",
       "                                                   DOD Father  ... parsedDOD  \\\n",
       "6                     breeding - xcas9 f, experimental   1732  ...       NaT   \n",
       "7    dispensible, check for pregnancies and euthani...   2065  ...       NaT   \n",
       "8                                          dispensible   2065  ...       NaT   \n",
       "9    dispensible, check for pregnancies and euthani...   2065  ...       NaT   \n",
       "10                                         dispensible   2065  ...       NaT   \n",
       "..                                                 ...    ...  ...       ...   \n",
       "251                                                  -   2550  ...       NaT   \n",
       "252                                                  -   2550  ...       NaT   \n",
       "253                                     breeder-backup   2728  ...       NaT   \n",
       "254                                      breeder-jun01   2728  ...       NaT   \n",
       "255                                        dispensible   2728  ...       NaT   \n",
       "\n",
       "    DispCount CageSize DispPercent E_num I_num S_num ina_num summedhgRNAs  \\\n",
       "6         0.0        1    0.000000   5.0  10.0  20.0    10.0         45.0   \n",
       "7         2.0        2    1.000000   NaN   NaN   NaN     NaN          0.0   \n",
       "8         2.0        2    1.000000   NaN   NaN   NaN     NaN          0.0   \n",
       "9         2.0        2    1.000000   NaN   NaN   NaN     NaN          0.0   \n",
       "10        2.0        2    1.000000   NaN   NaN   NaN     NaN          0.0   \n",
       "..        ...      ...         ...   ...   ...   ...     ...          ...   \n",
       "251       0.0        5    0.000000   NaN   NaN   NaN     NaN          0.0   \n",
       "252       0.0        5    0.000000   NaN   NaN   NaN     NaN          0.0   \n",
       "253       1.0        3    0.333333   NaN   NaN   NaN     NaN          0.0   \n",
       "254       1.0        3    0.333333   NaN   NaN   NaN     NaN          0.0   \n",
       "255       1.0        3    0.333333   NaN   NaN   NaN     NaN          0.0   \n",
       "\n",
       "    summedhgRNAs_active  \n",
       "6                  35.0  \n",
       "7                   0.0  \n",
       "8                   0.0  \n",
       "9                   0.0  \n",
       "10                  0.0  \n",
       "..                  ...  \n",
       "251                 0.0  \n",
       "252                 0.0  \n",
       "253                 0.0  \n",
       "254                 0.0  \n",
       "255                 0.0  \n",
       "\n",
       "[240 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .to_clipboard(index=False, sep = \"\\t\")\n",
    "df.query('DOD.str.contains(\"zack\")')[['Tag','Genotype', 'summedhgRNAs', 'summedhgRNAs_active']].to_csv('ZackTransferGenotypes.tsv', sep = '\\t', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## query each lineage + create CSV from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(df, lineage, disp=1):\n",
    "    result = df.query(\n",
    "        'Lineage.str.contains(\"{}\")'.format(lineage))\n",
    "    if disp:\n",
    "        result = result.query('DispPercent >= {}'.format(disp))\n",
    "    result = result.sort_values(\"summedhgRNAs_active\", ascending=False)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "frames = {}\n",
    "lineages = ['#3', '#7', 'ins21', '-Cas9', 'PBF']\n",
    "\n",
    "for line in lineages:\n",
    "    frame = query(df, line).head(5)\n",
    "    frames.update({line: frame})\n",
    "for frame in frames:\n",
    "    fn = makefn(frame)\n",
    "    frames[frame].to_csv(fn, sep=\"\\t\")\n",
    "    df[['fCas', 'transgene']] = df['Genotype'].str.split(\",\", 1, expand = True)\n",
    "frame = query(df, 'fCas9').query('transgene.str.contains(\"-\")')\n",
    "frame = frame.sort_values(['fCas', 'transgene'], ascending = [True, True]).head(10)\n",
    "fn = makefn('creFlipped-negative_ampliconSamples')\n",
    "frame.to_csv(fn, sep ='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# checking breedings against spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "source_dir = \"Breedings\"\n",
    "date = \"2020-05\"\n",
    "fns = glob.glob(source_dir + '/*{}*'.format(date))\n",
    "data = []\n",
    "\n",
    "for fn in fns:\n",
    "    frame = pd.read_csv(fn, sep=\"\\t\")\n",
    "    frame['Lineage'], frame['Date'] = fn[10:24].split(\"-\", 1)\n",
    "    data.append(frame)\n",
    "\n",
    "animals = pd.concat(\n",
    "    data, ignore_index=True)  #dont want pandas to try an align row indexes\n",
    "\n",
    "animals = animals.applymap(lambda x: x.strip(\"t\") if isinstance(\n",
    "    x, str) else x)  #remove t for easier comparison to big frame applys\n",
    "\n",
    "tagCols = ['Male', 'Female1',\n",
    "           'Female2']  #grab columns with animals for flattening\n",
    "data = []\n",
    "for col in tagCols:\n",
    "    frame = pd.concat((animals[i] for i in [col, 'Lineage', 'Date']),\n",
    "                      axis=1).rename({col: 'Tag'}, axis=1)\n",
    "    data.append(frame)\n",
    "\n",
    "#            #, animals['Lineage'], animals['Date']]\n",
    "# #     data.append(frame)\n",
    "breeders = pd.concat(\n",
    "    data, ignore_index=True)  #dont want pandas to try an align row indexes;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "## check that all animals are correctly marked in the spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'breeders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-89f131c66d50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## #### parsing breedings etc - check that all breeders are marked as such on the sheet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbreedrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbreeders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_on\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'TagClean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_on\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Tag'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'inner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbreedrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDOD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Not all breeders marked\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'breeders' is not defined"
     ]
    }
   ],
   "source": [
    "## #### parsing breedings etc - check that all breeders are marked as such on the sheet\n",
    "breedrs = pd.merge(df, breeders, left_on ='TagClean', right_on = 'Tag', how = 'inner')\n",
    "if len(breedrs.DOD.unique()) > 1:\n",
    "    print(\"Not all breeders marked\")\n",
    "else:\n",
    "    print(\"Only one DOD found, {}\".format(breedrs.DOD.unique()[0]))\n",
    "    \n",
    "list(set(breeders['Tag'])-set(breedrs['TagClean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# plate = df[plate].sort_values(['Column', 'Row'])\n",
    "# #.sort_values(\n",
    "#  #       ['Row',\n",
    "#   #       'Column']).reset_index(drop=True)  # impt standard plate indexing\n",
    "\n",
    "# plateNew = locs.merge(plate, how = 'outer')\n",
    "# df = plateNew\n",
    "\n",
    "# plateNew.pivot(index='Row', columns='Column',\n",
    "#                       values=['Info'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plate.Tag = df.Tag.apply(lambda x: \"t\" + str(x) if not x != x else 'empty')\n",
    "# plate['Info'] = ['\\n'.join([str(x), str(y)]) for x, y in zip(plate['Tag'], plate['Lineage'])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# assessing parental genotypes to consider offspring (for fCas9 maintenance/breeding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Lineage = df.Lineage.fillna(\"--\")\n",
    "fathers = df[df.Lineage.str.contains('fCas9')].Father.unique().flatten()\n",
    "mothers = df[df.Lineage.str.contains('fCas9')].Mother.unique().flatten()\n",
    "rents = np.append(fathers, mothers)\n",
    "parentList = []\n",
    "for i in rents:\n",
    "    parentList.extend(i.split(\"/\")) \n",
    "parents = df.loc[df['Tag'].isin(parentList)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## easy categories\n",
    "plateCats =  ['Genotype','PlateID', 'Row', 'Column',\n",
    "       'Position']\n",
    "cats = easyCats + plateCats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['fCas', 'transgene']] = df['Genotype'].str.split(\",\", 1, expand = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Lineage = df.Lineage.fillna(\"--\")\n",
    "linMask = df.Lineage.str.contains('fCas9')\n",
    "genoMask = df.Genotype.isnull()\n",
    "fCas9 = df[linMask].fillna(\"-\")\n",
    "H_linMask = fCas9.Lineage.str.contains('hCD2')\n",
    "S_linMask = fCas9.Lineage.str.lower().str.contains('syn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fCas9.groupby(['Sex', 'DOD', 'fCas', 'transgene']).agg({'Genotype': 'count',\n",
    "                                                   'Tag':'unique', 'Cage':'unique', \n",
    "                                                  'DOB': ['min', 'max']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cages = df.groupby([\"Cage\", \"Sex\"]).agg({'Color':'unique',\n",
    "                                         'DOD':'unique',\n",
    "                                         'Lineage':'unique'})   #yay!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Cage').agg({\n",
    "    'dispensible': 'mean',\n",
    "    'Cage': 'size',\n",
    "    'Sex': 'unique',\n",
    "    'DOD': 'unique',\n",
    "    'Tag': 'unique',\n",
    "    'Color': 'unique',\n",
    "    'Ear': 'unique',\n",
    "    'Lineage': 'unique'\n",
    "}).sort_values('dispensible', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.Sex == \"F\"].groupby(['Cage']).agg({'Cage': 'size',\n",
    "                                         'DOD': 'unique',\n",
    "                                         'Tag':'unique',\n",
    "                                        'Color' : 'unique',\n",
    "                                         'Ear' : 'unique',}).sort_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.Sex == \"F\"].groupby(['Cage']).agg({'Cage':'size',\n",
    "                                         'Color':'unique',\n",
    "                                         'DOD':'unique',\n",
    "                                         'Lineage':'unique'})   #yay!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# retrieve animals with null genotypes in a certain lineage + get their well plates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insGeno = df[(df.Lineage.str.contains(\"ins21\")) & (df.Genotype.isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs = pd.read_pickle('96-wellLocs.pkl').sort_values(\n",
    "        ['Column',\n",
    "         'Row']).reset_index(drop=True)  # impt standard plate indexing\n",
    "# locs.join(df, rsuffix = \"_init\")\n",
    "# insGeno.sort_values(join(locs, rsuffix = 'init')\n",
    "locs.join(insGeno, rsuffix='init')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insGeno.pivot(index='WellRow', columns='WellCol',\n",
    "                      values=['Tag', 'Plate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate a general colony pivot table by lineage, sex, and DOB with total numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveFn = makefn(file.replace(\" \", \"\")+'_summary')\n",
    "\n",
    "remapDict= {'ins': '1685ins21#2',\n",
    "            'pb3' : '1763PB#3',\n",
    "            'pb7' : '1763PB#7',\n",
    "            'pbf': '1853PBF#1'}\n",
    "for key, value in remapDict.items():\n",
    "    df.Lineage = df.Lineage.apply(lambda row: value if key in row.lower() else row)\n",
    "grouped = df.groupby(['Lineage',\n",
    "            'Sex',\n",
    "            pd.Grouper(key='DOB',freq='q')]).size().unstack('DOB').reset_index()\n",
    "grouped['Total'] = grouped.sum(axis=1)\n",
    "grouped.fillna(\"-\").to_csv(saveFn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveFn = makefn(file.replace(\" \", \"\")+'_femaleConsolidation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Cage\"]).agg({'Cage': 'count',  'Sex': 'unique',\n",
    "                                 'Color':'unique',\n",
    "                                'DOD': 'unique'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mating = tagSearch(ins + PB3 + PB7 + PBF + cre)\n",
    "df[mating].sort_values('Lineage').to_csv('file.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# break - 2019 and previous code snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CreMask = (df.Lineage.str.contains(\"fCas\", na=False))\n",
    "PBFMask = (df.Lineage.str.contains(\"PBF\", na=False))\n",
    "insMask = tagSearch(\"t2620 t2632 t2623 t2463 t2625 t2622 t2616 t2626 t2633 t2720 t2721 t2722 t2755 t2750 t2751 t2415 t2445\")\n",
    "alreadyShipped = (df.Cage.str.contains(\"HOP\", na= True))\n",
    "traveling = (df.DOD.str.endswith(\"hopkins| \", na = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipped_2 = df[(df.DOD.str.endswith(\"hopkins\", na = False))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipped_2.sort_values([\"Cage\", \"Tag\"])[['Cage', 'Sex', 'Tag', 'Ear', 'Color', 'DOB']].to_clipboard(excel=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shipped_2.groupby([\"Cage\"]).agg({'Cage': 'count', 'Sex':'unique'}).to_clipboard(excel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hop = df[((traveling & (CreMask | PBFMask)) | insMask ) & ~alreadyShipped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hop.groupby([\"Cage\", \"Sex\"]).agg({'Cage': 'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hop.groupby([\"Sex\", \"Cage\", \"Tag\"]).agg({'Lineage': 'unique',\n",
    "                                         'Color': 'unique',\n",
    "                                        'Ear': 'unique'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hop.groupby(['Sex','Cage']).agg({'Cage':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hop.sort_values(['Sex', \"Lineage\", 'Tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.Genotype.isnull()) \\\n",
    "   & (df['DOD'] != \"Dispensible\")].fillna(\"x\").groupby([\"Lineage\", 'Cage']).agg({'Sex': 'count',\n",
    "                                                                                   'Tag':'unique',\n",
    "                                                                                   'Name': 'unique' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask for sorting centrifuge tube samples\n",
    "freezerMask = (df.Tag.notnull()) & \\\n",
    "    (~df['Notebook info'].str.startswith(\"T|Plate\", na=False))&\\\n",
    "     (df.Lineage != 'J024858-Cas9')\n",
    "\n",
    "#and the results\n",
    "df[freezerMask].sort_values(\"Tag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyMask, lateMask, fMask = collectAgeRange(df, '2019-12-01',\n",
    "                                             28, 0 , \"\", \"F\")\n",
    "earlyMask, lateMask, mMask = collectAgeRange(df, '2019-12-01',\n",
    "                                             40, 0 , \"\", \"M\")\n",
    "\n",
    "inc = df[mMask].append(df[fMask]) #combine\n",
    "\n",
    "inc['DOD'], inc['parsedDOD'] =  zip(*inc.DOD.apply(lambda row: cleanDOD(row))) #parse DOD\n",
    "inc = inc[(~inc.parsedDOD.notnull()) \\\n",
    "          & (~inc.DOD.str.contains('sperm|Diss|f.d.',\n",
    "                                   na = False))] #drop assorted dead mice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc.fillna('n/a').groupby(['Lineage',\n",
    "                           'DOD',\n",
    "                           'Sex']).agg({'DOB': ['count',\n",
    "                                                'min',\n",
    "                                                'max']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc[inc.DOD.str.contains('Hopkins', na= False)].groupby(\"Sex\").agg({'Sex': 'count',\n",
    "                                                    'Cage': 'nunique'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noMice, noCages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.Plate == \"T885765\"].sort_values(['WellRow',\n",
    "                                       'WellCol'])[['Position',\n",
    "                                                    'Tag',\n",
    "                                                    'Lineage']].to_clipboard(excel=True, header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_coherent(seq):\n",
    "    return seq == range(seq[0], seq[-1]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MMRRC_cats = ['Tag',\n",
    "           'Cage',\n",
    "           'Ear',\n",
    "           'Sex',\n",
    "           'Color',\n",
    "           'Genotype',\n",
    "           'DOB',\n",
    "           'Lineage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# earlyMask, lateMask, mMask = collectAgeRange(df,\n",
    "#                                              '2019-09-16',\n",
    "#                                              13, 8,\n",
    "#                                              \"PB#\", \"M\")\n",
    "# earlyMask, lateMask, fMask = collectAgeRange(df, \n",
    "#                                              '2019-09-16',\n",
    "#                                              4, 1,\n",
    "#                                              \"PB#\", \"F\")\n",
    "# shippedMask = (df.DOD.str.contains(\"mrrc|opkins\",\n",
    "#                                    na=False)) & (df.Lineage.str.contains(\"PB#\")) #PBs marked for any maintenance movement\n",
    "\n",
    "# df[mMask|fMask|shippedMask].groupby([\"Lineage\",\n",
    "#                                      \"Sex\",\n",
    "#                                      \"DOD\"]).agg({'Tag':'count',\n",
    "#                                                    'DOB': ['first', 'last']}) #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dispense, cSorted = makeOutputs(df)\n",
    "cSorted.to_clipboard(excel=True, index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyMask, lateMask, incMask = collectAgeRange(df, '2019-09-16', 4, 1, \"\", \"F\")\n",
    "df[incMask][['Tag',\n",
    "             'Cage',\n",
    "             'Ear',\n",
    "             'Sex',\n",
    "             'Color',\n",
    "             'DOB',\n",
    "             'Genotype',\n",
    "             'Lineage']].groupby(\"Lineage\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "earlyMask, lateMask, incMask = collectAgeRange(df, '2019-10-04', 10, 0 , \"\", \"\")\n",
    "#inc = df[incMask]\n",
    "#inc = inc.fillna(\"BLANK\")\n",
    "\n",
    "# [['Tag',\n",
    "#              'Cage',\n",
    "#              'Ear',\n",
    "#              'Sex',\n",
    "#              'Color',\n",
    "#              'DOB',\n",
    "#              'Genotype',\n",
    "#              'Lineage']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df.DOD == 'Shipped to mmrrc on 9/10'][['Tag',\n",
    "#              'Color',\n",
    "#              'Ear',\n",
    "#              'Cage', \n",
    "#              'Sex',\n",
    "#              'Genotype',\n",
    "#              'DOB',\n",
    "#              'Lineage']].sort_values(by = ['Cage',\n",
    "#                                            'Tag'])\\\n",
    "#                 .fillna(\"missing\").to_clipboard(index = False,\n",
    "#                                                excel = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## MICE WITH UNKNOWN FATE\n",
    "# df[(df.DOD.isnull())].groupby([\"Lineage\", \"Cage\"]).agg({'DOB': ['max', \n",
    "#                                                              'min', \n",
    "#                                                              'count'],\n",
    "#                                                         'Sex': 'max',\n",
    "#                                                         'Name': 'unique'}).fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## selecting mice by age#########\n",
    "shipDate = '2019-09-16'\n",
    "early1, late1, mask1 = collectAgeRange(df, shipDate, 13, 8, \"PB#\", \"M\")\n",
    "early2, late2, mask2 = collectAgeRange(df, shipDate, 9, 6.5, \"PB#\", \"F\")\n",
    "\n",
    "males_20190916  = df[mask1].sort_values([\"Lineage\", \"Genotype\"])\n",
    "females_20190916 = df[mask2].sort_values([\"Lineage\", \"Genotype\"])\n",
    "\n",
    "shipment_20190916 = males_20190916.append(females_20190916)\n",
    "\n",
    "# Sep09_shipment.sort_values([\"Lineage\",\n",
    "#                             \"Sex\",\n",
    "#                             \"Cage\"]).to_clipboard(excel=True,\n",
    "#                                                   index = False)\n",
    "\n",
    "# Sep09_shipment.groupby([\"Lineage\",\n",
    "#                         \"Sex\",\n",
    "#                         \"Cage\"])['Tag',\n",
    "#                                  'Genotype'].count().to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_reseq.sort_values([\"Tag\"])[['Tag',\n",
    "                                  'Lineage',\n",
    "                                  'Plate',\n",
    "                                  'WellRow',\n",
    "                                  'WellCol']].to_clipboard(excel = True, index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tag'] = 't' + df['Tag'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KL14_plateB = df[df['Plate'].str\\\n",
    "   .contains(\"T885773|T885761\", na= False)]\\\n",
    "    .sort_values(by=['Plate', 'WellRow', 'WellCol']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KL14_plateB[['Tag','Lineage','Plate', 'WellRow', 'WellCol']]\\\n",
    "    .to_clipboard(excel=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KL14_plateA = df[df['Plate'].str\\\n",
    "   .contains(\"T885772\", na= False)]\\\n",
    "    .sort_values(by=['Plate', 'WellRow', 'WellCol']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Plate'].str\\\n",
    "   .contains(\"T88572|T885761|T885772|T885773\",\n",
    "             na = False)][['Tag', 'Plate', 'Well']]\\\n",
    "    .sort_values(by=['Plate', 'Well'])\\\n",
    "    .to_clipboard(excel=True, index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KL14_plateA[['Tag','Lineage','Plate', 'WellRow', 'WellCol']]\\\n",
    "    .to_clipboard(excel=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KL14_plateA.reindex('WellCol', method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "KL14_plateA.groupby('WellRow').Lineage.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KL14_plateA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KL14_plateA[['Tag', 'Plate', 'WellRow', 'WellCol']]\\\n",
    "    .sort_values(by=['Plate', 'WellRow', 'WellCol'])\\\n",
    "    .to_clipboard(excel=True, index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## lineage stats over time\n",
    "df.groupby([pd.Grouper(key=\"DOB\", freq = \"M\"),\n",
    "            \"Lineage\"]).Cage.count().unstack('DOB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfContains(string, column = \"Cage\", keep_empties = False, case = False, df = df):\n",
    "    '''given a cage number/s (formatted as \"nrbxxxx|nrbxxx\") etc, the indexes of entries where true'''\n",
    "    return df[column].str.contains(string, na = keep_empties, case = case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.DOD.str.contains(\"Sperm\", na = False)].groupby('Lineage').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(dfContains(\"1036|1037\"))\n",
    "   & (df.Sex == \"M\")][['Tag',\n",
    "                      'Cage',\n",
    "                       'Ear',\n",
    "                       'Sex',\n",
    "                       'DOB',\n",
    "                       'Notes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PB = ['1763PB#7', '1763PB#3']\n",
    "counted = df.groupby(\"Cage\").size().reset_index(name = 'Total')\n",
    "df = df.merge(counted)\n",
    "PB_solo_males = df[(df.Lineage.isin(PB))&(df.Sex == \"M\")&(df.Total == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
